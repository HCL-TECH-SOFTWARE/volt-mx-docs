<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>The source code</title>
  <link href="../resources/prettify/prettify.css" type="text/css" rel="stylesheet" />
  <script type="text/javascript" src="../resources/prettify/prettify.js"></script>
  <style type="text/css">
    .highlight { display: block; background-color: #ddd; }
  </style>
  <script type="text/javascript">
    function highlight() {
      document.getElementById(location.hash.replace(/#/, "")).className = "highlight";
    }
  </script>
</head>
<body onload="prettyPrint(); highlight();">
  <pre class="prettyprint lang-js"><span id='android-media-AudioTimestamp'>/**@class android.media.AudioTimestamp
</span>@extends java.lang.Object

 Structure that groups a position in frame units relative to an assumed audio stream,
 together with the estimated time when that frame enters or leaves the audio
 processing pipeline on that device. This can be used to coordinate events
 and interactions with the external environment.
 &lt;p&gt;
 The time is based on the implementation's best effort, using whatever knowledge
 is available to the system, but cannot account for any delay unknown to the implementation.

 @see AudioTrack#getTimestamp AudioTrack.getTimestamp(AudioTimestamp)
 @see AudioRecord#getTimestamp AudioRecord.getTimestamp(AudioTimestamp, int)
*/
var AudioTimestamp = {

<span id='android-media-AudioTimestamp-property-TIMEBASE_MONOTONIC'>/** Clock monotonic or its equivalent on the system,
</span> in the same units and timebase as {@link java.lang.System#nanoTime}.
*/
TIMEBASE_MONOTONIC : &quot;0&quot;,
<span id='android-media-AudioTimestamp-property-TIMEBASE_BOOTTIME'>/** Clock monotonic including suspend time or its equivalent on the system,
</span> in the same units and timebase as {@link android.os.SystemClock#elapsedRealtimeNanos}.
*/
TIMEBASE_BOOTTIME : &quot;1&quot;,
<span id='android-media-AudioTimestamp-property-framePosition'>/** Position in frames relative to start of an assumed audio stream.
</span> &lt;p&gt;
 When obtained through
 {@link android.media.AudioRecord#getTimestamp android.media.AudioRecord.getTimestamp(AudioTimestamp, int)},
 all 64 bits of position are valid.
 &lt;p&gt;
 When obtained through
 {@link android.media.AudioTrack#getTimestamp android.media.AudioTrack.getTimestamp(AudioTimestamp)},
 the low-order 32 bits of position is in wrapping frame units similar to
 {@link android.media.AudioTrack#getPlaybackHeadPosition android.media.AudioTrack.getPlaybackHeadPosition()}.
*/
framePosition : &quot;null&quot;,
<span id='android-media-AudioTimestamp-property-nanoTime'>/** Time associated with the frame in the audio pipeline.
</span> &lt;p&gt;
 When obtained through
 {@link android.media.AudioRecord#getTimestamp android.media.AudioRecord.getTimestamp(AudioTimestamp, int)},
 this is the estimated time in nanoseconds when the frame referred to by
 {@link #framePosition} was captured. The timebase is either
 {@link #TIMEBASE_MONOTONIC} or {@link #TIMEBASE_BOOTTIME}, depending
 on the timebase parameter used in
 {@link android.media.AudioRecord#getTimestamp android.media.AudioRecord.getTimestamp(AudioTimestamp, int)}.
 &lt;p&gt;
 When obtained through
 {@link android.media.AudioTrack#getTimestamp android.media.AudioTrack.getTimestamp(AudioTimestamp)},
 this is the estimated time when the frame was presented or is committed to be presented,
 with a timebase of {@link #TIMEBASE_MONOTONIC}.
*/
nanoTime : &quot;null&quot;,

};</pre>
</body>
</html>
